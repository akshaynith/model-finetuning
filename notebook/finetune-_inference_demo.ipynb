{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2b9c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e2d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device count: 1\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d40f344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import torch, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf09b582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a440b5f25a4427e89f50fb2040bb16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "BASE_ID = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "ADAPTER_DIR = \"phi3mini-agnews-smoke-adapters\"  # <- your saved adapters folder\n",
    "\n",
    "bnb = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=\"bfloat16\"  # if this errors on your setup, change to \"float16\"\n",
    ")\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(BASE_ID, use_fast=True)\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_ID,\n",
    "    quantization_config=bnb,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(base, ADAPTER_DIR)\n",
    "model.eval()\n",
    "print(\"Loaded on:\", model.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4470d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "\n",
    "def classify_news(text: str, max_new_tokens: int = 6):\n",
    "    prompt = (\n",
    "        \"### Instruction:\\n\"\n",
    "        \"Classify the news into one of: World, Sports, Business, Sci/Tech. \"\n",
    "        \"Answer with the label only.\\n\\n\"\n",
    "        \"### Input:\\n\"\n",
    "        f\"{text.strip()}\\n\\n\"\n",
    "        \"### Response:\\n\"\n",
    "    )\n",
    "    inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tok.eos_token_id,\n",
    "            pad_token_id=tok.pad_token_id,\n",
    "        )\n",
    "\n",
    "    full = tok.decode(out[0], skip_special_tokens=True)\n",
    "    # keep only the first line after \"### Response:\"\n",
    "    after = full.split(\"### Response:\")[-1].strip()\n",
    "    label = after.splitlines()[0].strip()\n",
    "\n",
    "    # light cleanup: strip punctuation/extra words\n",
    "    label = re.sub(r\"[^A-Za-z/]+\", \" \", label).strip()\n",
    "    # optional: map close variants to canonical labels\n",
    "    canon = min(LABELS, key=lambda L: len(set(L.lower()) - set(label.lower())))\n",
    "    return label, canon, full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9d3bded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akshaysi\\anaconda3\\envs\\deepl_ml_env\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:89: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: India's benchmark indices rallied as IT and banking stocks gained after the policy announcement.\n",
      "Pred: Business  |  Canon: Business\n",
      "\n",
      "Text: NASA confirms the rover discovered hydrated minerals on Mars.\n",
      "Pred: Sci/Tech  |  Canon: Sci/Tech\n",
      "\n",
      "Text: Manchester City secured a 2-0 win with a late brace from Haaland.\n",
      "Pred: Sports  |  Canon: Sports\n",
      "\n",
      "Text: Oil prices fell as OPEC signaled potential output increases.\n",
      "Pred: Business  |  Canon: Business\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    \"India's benchmark indices rallied as IT and banking stocks gained after the policy announcement.\",\n",
    "    \"NASA confirms the rover discovered hydrated minerals on Mars.\",\n",
    "    \"Manchester City secured a 2-0 win with a late brace from Haaland.\",\n",
    "    \"Oil prices fell as OPEC signaled potential output increases.\"\n",
    "]\n",
    "\n",
    "for s in samples:\n",
    "    label, canon, raw = classify_news(s)\n",
    "    print(f\"\\nText: {s}\\nPred: {label}  |  Canon: {canon}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99697396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are concise and helpful. Classify: 'Indexes rally as banks surge after policy.' Respond with one label: World, Sports, Business, Sci/Tech. Business\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ask_one(messages, max_new_tokens=64):\n",
    "    prompt = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    x = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    y = model.generate(**x, max_new_tokens=max_new_tokens, do_sample=False,\n",
    "                       eos_token_id=tok.eos_token_id, pad_token_id=tok.pad_token_id)\n",
    "    return tok.decode(y[0], skip_special_tokens=True)\n",
    "\n",
    "ask_one([\n",
    "    {\"role\": \"system\", \"content\": \"You are concise and helpful.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Classify: 'Indexes rally as banks surge after policy.' Respond with one label: World, Sports, Business, Sci/Tech.\"}\n",
    "], max_new_tokens=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c33738f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are concise and helpful. Classify: 'Indexes rally as banks surge after policy.' Respond with one label: World, Sports, Business, Sci/Tech. Business\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_one(\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"You are concise and helpful.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Classify: 'Indexes rally as banks surge after policy.' Respond with one label: World, Sports, Business, Sci/Tech.\"}\n",
    "    ],\n",
    "    max_new_tokens=6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffaf149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "LABELS = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    # normalize for robust matching (case/punct/space insensitive)\n",
    "    return re.sub(r\"[^a-z]\", \"\", s.lower())\n",
    "\n",
    "def snap_to_label(raw: str) -> str:\n",
    "    # take only the first line\n",
    "    line = raw.strip().splitlines()[0]\n",
    "    n = _norm(line)\n",
    "    # exact canonical match first\n",
    "    for L in LABELS:\n",
    "        if _norm(L) == n:\n",
    "            return L\n",
    "    # contains canonical token\n",
    "    for L in LABELS:\n",
    "        if _norm(L) in n or n in _norm(L):\n",
    "            return L\n",
    "    # last resort: regex search in raw\n",
    "    m = re.search(r\"\\b(World|Sports|Business|Sci/?Tech)\\b\", raw, flags=re.I)\n",
    "    return m.group(0).replace(\"SciTech\",\"Sci/Tech\") if m else line\n",
    "\n",
    "def classify_one(text: str, max_new_tokens: int = 4) -> str:\n",
    "    # Use the same SFT prompt style we trained on and force short output\n",
    "    prompt = (\n",
    "        \"### Instruction:\\n\"\n",
    "        \"Classify the news into exactly one of these labels: World, Sports, Business, Sci/Tech.\\n\"\n",
    "        \"Output the label onlyâ€”no extra words.\\n\\n\"\n",
    "        \"### Input:\\n\"\n",
    "        f\"{text.strip()}\\n\\n\"\n",
    "        \"### Response:\\n\"\n",
    "    )\n",
    "    x = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    y = model.generate(\n",
    "        **x,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        eos_token_id=tok.eos_token_id,\n",
    "        pad_token_id=tok.pad_token_id,\n",
    "    )\n",
    "    out = tok.decode(y[0], skip_special_tokens=True)\n",
    "    # Keep only what's after \"### Response:\" and snap to canonical label\n",
    "    after = out.split(\"### Response:\")[-1]\n",
    "    return snap_to_label(after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fc81727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sci/Tech'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_one(\"NASA confirms the rover discovered hydrated minerals on Mars.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1712831e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sports'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_one(\"Manchester City won 2-0 with a late brace from Haaland.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dd22cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Business'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_one(\"Oil prices fell as OPEC signaled potential output increases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "623952d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Indices rallied as banking stocks surged after the policy announcement.',\n",
       "  'Business'),\n",
       " ('OpenAI releases a new small language model for on-device use.', 'Sci/Tech'),\n",
       " ('India defeats Australia in a last-over thriller.', 'Sports')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Indices rallied as banking stocks surged after the policy announcement.\",\n",
    "    \"OpenAI releases a new small language model for on-device use.\",\n",
    "    \"India defeats Australia in a last-over thriller.\"\n",
    "]\n",
    "[ (t, classify_one(t)) for t in texts ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c33bbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sports'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_one(\"India have to chase 200 runs in one-day match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07948673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepl_ml_env)",
   "language": "python",
   "name": "deepl_ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
